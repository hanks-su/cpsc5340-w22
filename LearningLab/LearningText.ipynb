{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Example:  Predict Review Score Based on Its Text\n",
    "\n",
    "* Get a sample of reviews from our Amazon data set\n",
    "* How accurately can we classify a new review based on fields different from its score?\n",
    "\n",
    "First re-cast the problem\n",
    "* Original problem is a regression problem -- predict score value\n",
    "* This often does not work in practice, the difference between 2 and 3, and 3 and 4 often cannot be predicted from the review summary and body.\n",
    "\n",
    "Quantize the problem\n",
    "* Score of 1 and 2 are \"bad\" reviews\n",
    "* Score f 4 and 5 are \"good\" reviews\n",
    "* Problem becomes a classification problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------\n",
    "\n",
    "**First steps**\n",
    "\n",
    "* Gather a set of training examples\n",
    "* Reformat them to make them ready to use with a learning algorithm\n",
    "\n",
    "The file \"reviews.txt\" was just sampled from the reviews collection, \n",
    "from reviews with scores of 1,2,4, and 5. The sampling tried to get approx 1000 positive and 1000 \n",
    "negative training examples.   \n",
    "\n",
    "The full set isn't really equally balanced -- in the full set, positive is about 5 to 1 over negative -- and dealing with imbalanced classes is a real issue, but we will ignore class imbalance for this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training(filename=\"reviews.txt\"):\n",
    "    training = []\n",
    "    for line in open(filename):\n",
    "        training.append(eval('(' + line + ')'))\n",
    "    return training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2973\n"
     ]
    }
   ],
   "source": [
    "raw_training = load_training()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.DataFrame.from_records(raw_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A007549913T3THC2E44K5</td>\n",
       "      <td>B0046ZHQAW</td>\n",
       "      <td>Marce</td>\n",
       "      <td>[3, 4]</td>\n",
       "      <td>is a very good iron, your hair look beautiful ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Really good one</td>\n",
       "      <td>1366329600</td>\n",
       "      <td>04 19, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A03666331WS5WUZMM0AUD</td>\n",
       "      <td>B00007M0CP</td>\n",
       "      <td>Susanne Gonzalez Delgado</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>Good quality for this Price. The curls gets qu...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Conair Xtreme Instant Heat Multisized Hot Roll...</td>\n",
       "      <td>1378080000</td>\n",
       "      <td>09 2, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A03898972RKS9HXS4H1F3</td>\n",
       "      <td>B002610SB2</td>\n",
       "      <td>Nancy Denise Graves</td>\n",
       "      <td>[4, 5]</td>\n",
       "      <td>The shirt fits perfectly--true to size.  It is...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>It was exactly what I was looking for!</td>\n",
       "      <td>1358726400</td>\n",
       "      <td>01 21, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A04051149NH0IDZZ4FH7</td>\n",
       "      <td>B002610SB2</td>\n",
       "      <td>Donnie</td>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>Wife hates hot days, well we live in florida.....</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Nice shirt for the wife</td>\n",
       "      <td>1394755200</td>\n",
       "      <td>03 14, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A06263011FDVMGFVAALWO</td>\n",
       "      <td>B00007M0CP</td>\n",
       "      <td>Hannah Moss</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>So much faster for me than using a curling iro...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I love them!</td>\n",
       "      <td>1365984000</td>\n",
       "      <td>04 15, 2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              reviewerID        asin              reviewerName helpful  \\\n",
       "0  A007549913T3THC2E44K5  B0046ZHQAW                     Marce  [3, 4]   \n",
       "1  A03666331WS5WUZMM0AUD  B00007M0CP  Susanne Gonzalez Delgado  [3, 3]   \n",
       "2  A03898972RKS9HXS4H1F3  B002610SB2       Nancy Denise Graves  [4, 5]   \n",
       "3   A04051149NH0IDZZ4FH7  B002610SB2                    Donnie  [4, 4]   \n",
       "4  A06263011FDVMGFVAALWO  B00007M0CP               Hannah Moss  [0, 0]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  is a very good iron, your hair look beautiful ...      5.0   \n",
       "1  Good quality for this Price. The curls gets qu...      5.0   \n",
       "2  The shirt fits perfectly--true to size.  It is...      5.0   \n",
       "3  Wife hates hot days, well we live in florida.....      5.0   \n",
       "4  So much faster for me than using a curling iro...      5.0   \n",
       "\n",
       "                                             summary  unixReviewTime  \\\n",
       "0                                    Really good one      1366329600   \n",
       "1  Conair Xtreme Instant Heat Multisized Hot Roll...      1378080000   \n",
       "2             It was exactly what I was looking for!      1358726400   \n",
       "3                            Nice shirt for the wife      1394755200   \n",
       "4                                       I love them!      1365984000   \n",
       "\n",
       "    reviewTime  \n",
       "0  04 19, 2013  \n",
       "1   09 2, 2013  \n",
       "2  01 21, 2013  \n",
       "3  03 14, 2014  \n",
       "4  04 15, 2013  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "asins = reviews.asin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.drop(['reviewerID', 'asin', 'reviewerName', 'unixReviewTime', 'reviewTime'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is a very good iron, your hair look beautiful ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Really good one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good quality for this Price. The curls gets qu...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Conair Xtreme Instant Heat Multisized Hot Roll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The shirt fits perfectly--true to size.  It is...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>It was exactly what I was looking for!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wife hates hot days, well we live in florida.....</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Nice shirt for the wife</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>So much faster for me than using a curling iro...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I love them!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  overall  \\\n",
       "0  is a very good iron, your hair look beautiful ...      5.0   \n",
       "1  Good quality for this Price. The curls gets qu...      5.0   \n",
       "2  The shirt fits perfectly--true to size.  It is...      5.0   \n",
       "3  Wife hates hot days, well we live in florida.....      5.0   \n",
       "4  So much faster for me than using a curling iro...      5.0   \n",
       "\n",
       "                                             summary  \n",
       "0                                    Really good one  \n",
       "1  Conair Xtreme Instant Heat Multisized Hot Roll...  \n",
       "2             It was exactly what I was looking for!  \n",
       "3                            Nice shirt for the wife  \n",
       "4                                       I love them!  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0    1712\n",
       "4.0     604\n",
       "3.0     286\n",
       "1.0     228\n",
       "2.0     143\n",
       "Name: overall, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.overall.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What fields should be our independent (X) variables?  \n",
    "Convert data frame:  include only desired X variables, and code the y variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = reviews[reviews.overall != 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_training = np.delete(raw_training, list(map(lambda j: j['overall'] == 3.0, raw_training)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0    1712\n",
       "4.0     604\n",
       "1.0     228\n",
       "2.0     143\n",
       "Name: overall, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.overall.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = list(map(lambda s: 0 if s < 3 else 1, reviews.overall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.drop(['overall'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2687, 3)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[3, 4]</td>\n",
       "      <td>is a very good iron, your hair look beautiful ...</td>\n",
       "      <td>Really good one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>Good quality for this Price. The curls gets qu...</td>\n",
       "      <td>Conair Xtreme Instant Heat Multisized Hot Roll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[4, 5]</td>\n",
       "      <td>The shirt fits perfectly--true to size.  It is...</td>\n",
       "      <td>It was exactly what I was looking for!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>Wife hates hot days, well we live in florida.....</td>\n",
       "      <td>Nice shirt for the wife</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>So much faster for me than using a curling iro...</td>\n",
       "      <td>I love them!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  helpful                                         reviewText  \\\n",
       "0  [3, 4]  is a very good iron, your hair look beautiful ...   \n",
       "1  [3, 3]  Good quality for this Price. The curls gets qu...   \n",
       "2  [4, 5]  The shirt fits perfectly--true to size.  It is...   \n",
       "3  [4, 4]  Wife hates hot days, well we live in florida.....   \n",
       "4  [0, 0]  So much faster for me than using a curling iro...   \n",
       "\n",
       "                                             summary  \n",
       "0                                    Really good one  \n",
       "1  Conair Xtreme Instant Heat Multisized Hot Roll...  \n",
       "2             It was exactly what I was looking for!  \n",
       "3                            Nice shirt for the wife  \n",
       "4                                       I love them!  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews['text'] = reviews.reviewText + reviews.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[3, 4]</td>\n",
       "      <td>is a very good iron, your hair look beautiful ...</td>\n",
       "      <td>Really good one</td>\n",
       "      <td>is a very good iron, your hair look beautiful ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>Good quality for this Price. The curls gets qu...</td>\n",
       "      <td>Conair Xtreme Instant Heat Multisized Hot Roll...</td>\n",
       "      <td>Good quality for this Price. The curls gets qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[4, 5]</td>\n",
       "      <td>The shirt fits perfectly--true to size.  It is...</td>\n",
       "      <td>It was exactly what I was looking for!</td>\n",
       "      <td>The shirt fits perfectly--true to size.  It is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>Wife hates hot days, well we live in florida.....</td>\n",
       "      <td>Nice shirt for the wife</td>\n",
       "      <td>Wife hates hot days, well we live in florida.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>So much faster for me than using a curling iro...</td>\n",
       "      <td>I love them!</td>\n",
       "      <td>So much faster for me than using a curling iro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  helpful                                         reviewText  \\\n",
       "0  [3, 4]  is a very good iron, your hair look beautiful ...   \n",
       "1  [3, 3]  Good quality for this Price. The curls gets qu...   \n",
       "2  [4, 5]  The shirt fits perfectly--true to size.  It is...   \n",
       "3  [4, 4]  Wife hates hot days, well we live in florida.....   \n",
       "4  [0, 0]  So much faster for me than using a curling iro...   \n",
       "\n",
       "                                             summary  \\\n",
       "0                                    Really good one   \n",
       "1  Conair Xtreme Instant Heat Multisized Hot Roll...   \n",
       "2             It was exactly what I was looking for!   \n",
       "3                            Nice shirt for the wife   \n",
       "4                                       I love them!   \n",
       "\n",
       "                                                text  \n",
       "0  is a very good iron, your hair look beautiful ...  \n",
       "1  Good quality for this Price. The curls gets qu...  \n",
       "2  The shirt fits perfectly--true to size.  It is...  \n",
       "3  Wife hates hot days, well we live in florida.....  \n",
       "4  So much faster for me than using a curling iro...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2687, 4)\n",
      "2687\n"
     ]
    }
   ],
   "source": [
    "print(reviews.shape)\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a text field as our X, and we have to convert it to a real input vector.\n",
    "First look at CountVectorizer:  https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#v = CountVectorizer(min_df=2)\n",
    "v = CountVectorizer(max_df=.75)\n",
    "X = v.fit_transform(reviews.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Side step:  look at excluding very rare terms (min_df) and very common terms (max_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is': 7355,\n",
       " 'very': 14697,\n",
       " 'good': 6045,\n",
       " 'iron': 7340,\n",
       " 'your': 15318,\n",
       " 'hair': 6283,\n",
       " 'look': 8150,\n",
       " 'beautiful': 1510,\n",
       " 'in': 6970,\n",
       " 'just': 7557,\n",
       " 'one': 9456,\n",
       " 'pass': 9806,\n",
       " 'does': 4240,\n",
       " 'not': 9252,\n",
       " 'hurt': 6807,\n",
       " 'it': 7377,\n",
       " 'all': 747,\n",
       " 'can': 2235,\n",
       " 'sayreally': 11830,\n",
       " 'quality': 10774,\n",
       " 'for': 5571,\n",
       " 'this': 13791,\n",
       " 'price': 10470,\n",
       " 'curls': 3533,\n",
       " 'gets': 5922,\n",
       " 'quite': 10815,\n",
       " 'tight': 13870,\n",
       " 'if': 6870,\n",
       " 'you': 15309,\n",
       " 'have': 6412,\n",
       " 'eacute': 4469,\n",
       " 'dium': 4197,\n",
       " 'long': 8140,\n",
       " 'now': 9287,\n",
       " 'longer': 8141,\n",
       " 'results': 11394,\n",
       " 'looks': 8155,\n",
       " 'better': 1626,\n",
       " 'as': 1109,\n",
       " 'more': 8863,\n",
       " 'natural': 9054,\n",
       " 'only': 9471,\n",
       " 'thing': 13775,\n",
       " 'dislike': 4151,\n",
       " 'that': 13721,\n",
       " 'my': 8988,\n",
       " 'fingers': 5378,\n",
       " 'get': 5918,\n",
       " 'constantly': 3139,\n",
       " 'burned': 2124,\n",
       " 'guess': 6225,\n",
       " 'am': 802,\n",
       " 'at': 1168,\n",
       " 'but': 2147,\n",
       " 'would': 15220,\n",
       " 'be': 1480,\n",
       " 'gread': 6144,\n",
       " 'came': 2215,\n",
       " 'with': 15134,\n",
       " 'special': 12764,\n",
       " 'glove': 6009,\n",
       " 'to': 13920,\n",
       " 'avoid': 1271,\n",
       " 'top': 13972,\n",
       " 'product': 10537,\n",
       " 'definitely': 3761,\n",
       " 'recommend': 11038,\n",
       " 'conair': 3012,\n",
       " 'xtreme': 15272,\n",
       " 'instant': 7176,\n",
       " 'heat': 6483,\n",
       " 'multisized': 8950,\n",
       " 'hot': 6728,\n",
       " 'rollers': 11600,\n",
       " 'pink': 10096,\n",
       " 'shirt': 12246,\n",
       " 'fits': 5407,\n",
       " 'perfectly': 9938,\n",
       " 'true': 14190,\n",
       " 'size': 12439,\n",
       " 'easy': 4506,\n",
       " 'care': 2305,\n",
       " 'never': 9153,\n",
       " 'needs': 9109,\n",
       " 'ironing': 7344,\n",
       " 'will': 15086,\n",
       " 'buying': 2161,\n",
       " 'near': 9081,\n",
       " 'future': 5795,\n",
       " 'great': 6148,\n",
       " 'buy': 2157,\n",
       " 'was': 14894,\n",
       " 'exactly': 4956,\n",
       " 'what': 15006,\n",
       " 'looking': 8154,\n",
       " 'wife': 15074,\n",
       " 'hates': 6404,\n",
       " 'days': 3659,\n",
       " 'well': 14986,\n",
       " 'we': 14939,\n",
       " 'live': 8076,\n",
       " 'florida': 5498,\n",
       " 'keeps': 7595,\n",
       " 'her': 6541,\n",
       " 'nagging': 9012,\n",
       " 'down': 4298,\n",
       " 'minimum': 8713,\n",
       " 'she': 12198,\n",
       " 'dosn': 4286,\n",
       " 'complain': 2962,\n",
       " 'about': 401,\n",
       " 'being': 1566,\n",
       " 'sweaty': 13419,\n",
       " 'nice': 9169,\n",
       " 'so': 12609,\n",
       " 'much': 8928,\n",
       " 'faster': 5235,\n",
       " 'me': 8518,\n",
       " 'than': 13711,\n",
       " 'using': 14586,\n",
       " 'curling': 3532,\n",
       " 'curl': 3527,\n",
       " 'everyday': 4930,\n",
       " 'love': 8195,\n",
       " 'these': 13764,\n",
       " 'they': 13767,\n",
       " 're': 10925,\n",
       " 'worth': 15216,\n",
       " 'them': 13736,\n",
       " 'when': 15015,\n",
       " 'dogs': 4246,\n",
       " 'gobble': 6024,\n",
       " 'treats': 14123,\n",
       " '60': 298,\n",
       " 'then': 13745,\n",
       " 'know': 7690,\n",
       " 'are': 1052,\n",
       " 'taste': 13560,\n",
       " 'priced': 10472,\n",
       " 'right': 11505,\n",
       " 'too': 13960,\n",
       " 'give': 5962,\n",
       " 'paws': 9865,\n",
       " 'up': 14530,\n",
       " 'like': 8002,\n",
       " 'police': 10236,\n",
       " 'drama': 4326,\n",
       " 'shows': 12298,\n",
       " 'old': 9438,\n",
       " 'school': 11873,\n",
       " '90': 349,\n",
       " 'show': 12292,\n",
       " 'writer': 15242,\n",
       " 'many': 8387,\n",
       " 'actors': 526,\n",
       " 'real': 10953,\n",
       " 'life': 7977,\n",
       " 'events': 4919,\n",
       " 'outstanding': 9622,\n",
       " 'series': 12092,\n",
       " 'cd': 2400,\n",
       " 'bargain': 1416,\n",
       " 'breath': 1960,\n",
       " 'of': 9402,\n",
       " 'fresh': 5698,\n",
       " 'air': 703,\n",
       " 'few': 5316,\n",
       " 'songs': 12679,\n",
       " 'were': 14994,\n",
       " 'on': 9452,\n",
       " '1982': 134,\n",
       " 'sampler': 11767,\n",
       " 'lp': 8222,\n",
       " 'from': 5728,\n",
       " 'record': 11048,\n",
       " 'company': 2934,\n",
       " 'irs': 7354,\n",
       " 'total': 13996,\n",
       " '22': 177,\n",
       " 'tracks': 14032,\n",
       " 'an': 852,\n",
       " 'extravaganza': 5117,\n",
       " 'early': 4481,\n",
       " 'by': 2168,\n",
       " 'new': 9155,\n",
       " 'wave': 14929,\n",
       " 'bands': 1400,\n",
       " 'rather': 10896,\n",
       " 'list': 8053,\n",
       " 'groups': 6211,\n",
       " 'enough': 4758,\n",
       " 'ensure': 4766,\n",
       " 'any': 945,\n",
       " '80s': 329,\n",
       " 'post': 10315,\n",
       " 'punk': 10708,\n",
       " 'fan': 5200,\n",
       " 'go': 6020,\n",
       " 'gos': 6060,\n",
       " 'wayne': 14935,\n",
       " 'county': 3338,\n",
       " 'electric': 4599,\n",
       " 'chairs': 2456,\n",
       " 'wazmo': 14938,\n",
       " 'nariz': 9031,\n",
       " 'root': 11622,\n",
       " 'boy': 1912,\n",
       " 'slim': 12502,\n",
       " 'skafish': 12443,\n",
       " 'john': 7500,\n",
       " 'cale': 2194,\n",
       " 'oingo': 9431,\n",
       " 'boingo': 1816,\n",
       " 'lad': 7740,\n",
       " 'klark': 7671,\n",
       " 'kent': 7609,\n",
       " 'stewart': 13022,\n",
       " 'copeland': 3263,\n",
       " 'before': 1539,\n",
       " 'he': 6435,\n",
       " 'founded': 5632,\n",
       " 'buzzcocks': 2164,\n",
       " 'english': 4737,\n",
       " 'beat': 1499,\n",
       " 'cramps': 3381,\n",
       " 'magazine': 8289,\n",
       " 'wall': 14846,\n",
       " 'voodoo': 14801,\n",
       " 'mexican': 8643,\n",
       " 'radio': 10843,\n",
       " 'alarm': 723,\n",
       " 'dr': 4318,\n",
       " 'medics': 8553,\n",
       " 'lords': 8169,\n",
       " 'church': 2631,\n",
       " 'timbuk': 13883,\n",
       " 'fine': 5370,\n",
       " 'young': 15313,\n",
       " 'cannibals': 2255,\n",
       " 'caterwaul': 2377,\n",
       " 'concrete': 3040,\n",
       " 'blonde': 1755,\n",
       " 'see': 12014,\n",
       " 'told': 13941,\n",
       " 'inclusive': 6994,\n",
       " 'period': 9953,\n",
       " 'faves': 5253,\n",
       " 'some': 12662,\n",
       " 'familiar': 5193,\n",
       " 'other': 9573,\n",
       " 'want': 14864,\n",
       " 'intro': 7280,\n",
       " 'late': 7800,\n",
       " '70s': 316,\n",
       " 'scene': 11856,\n",
       " 'enjoy': 4745,\n",
       " 'note': 9257,\n",
       " 'had': 6278,\n",
       " 'fave': 5252,\n",
       " 'teaser': 13596,\n",
       " 'shubargain': 12308,\n",
       " 'mostly': 8872,\n",
       " 'rare': 10887,\n",
       " 'performances': 9943,\n",
       " 'vibrant': 14709,\n",
       " 'color': 2851,\n",
       " 'soft': 12627,\n",
       " 'material': 8472,\n",
       " 'something': 12668,\n",
       " 'make': 8325,\n",
       " 'stand': 12922,\n",
       " 'out': 9583,\n",
       " 'crowd': 3465,\n",
       " 'through': 13832,\n",
       " 'bright': 1995,\n",
       " 'there': 13756,\n",
       " 'products': 10543,\n",
       " 'limited': 8018,\n",
       " 'their': 13734,\n",
       " 'applications': 999,\n",
       " 'bougth': 1889,\n",
       " 'because': 1517,\n",
       " 'flashligth': 5438,\n",
       " 'used': 14570,\n",
       " 'couldn': 3325,\n",
       " 'where': 15017,\n",
       " 'broken': 2024,\n",
       " 'ended': 4709,\n",
       " '4a': 262,\n",
       " 'batteries': 1463,\n",
       " 'don': 4262,\n",
       " 'need': 9101,\n",
       " 'dog': 4244,\n",
       " 'leave': 7883,\n",
       " 'everyone': 4933,\n",
       " 'alone': 772,\n",
       " '20': 151,\n",
       " 'minutes': 8726,\n",
       " 'kong': 7703,\n",
       " 'treat': 14118,\n",
       " 'prepared': 10427,\n",
       " 'advance': 603,\n",
       " 'cow': 3360,\n",
       " 'bone': 1828,\n",
       " 'doesn': 4241,\n",
       " 'even': 4911,\n",
       " 'last': 7792,\n",
       " 'wrong': 15249,\n",
       " 'side': 12323,\n",
       " 'those': 13801,\n",
       " 'teeth': 13621,\n",
       " 'here': 6542,\n",
       " 'how': 6745,\n",
       " 'put': 10739,\n",
       " 'akong': 720,\n",
       " 'stuff': 13181,\n",
       " 'snacks': 12580,\n",
       " 'liver': 8079,\n",
       " '11': 31,\n",
       " 'ounce': 9578,\n",
       " 'largein': 7785,\n",
       " 'toy': 14020,\n",
       " 'paste': 9823,\n",
       " 'around': 1078,\n",
       " 'sometimes': 12671,\n",
       " 'fill': 5345,\n",
       " 'way': 14934,\n",
       " 'also': 780,\n",
       " 'leftover': 7898,\n",
       " 'meat': 8539,\n",
       " 'or': 9523,\n",
       " 'fish': 5400,\n",
       " 'short': 12269,\n",
       " 'order': 9536,\n",
       " 'freezer': 5687,\n",
       " 'against': 664,\n",
       " 'day': 3654,\n",
       " 'driving': 4384,\n",
       " 'crazy': 3396,\n",
       " 'takes': 13506,\n",
       " 'freeze': 5686,\n",
       " 'same': 11762,\n",
       " 'distraction': 4190,\n",
       " 'shoes': 12255,\n",
       " 've': 14651,\n",
       " 'gotten': 6070,\n",
       " 'ton': 13951,\n",
       " 'compliments': 2982,\n",
       " 'purchased': 10717,\n",
       " 'wear': 14947,\n",
       " 'cheerleading': 2538,\n",
       " 'aerobic': 628,\n",
       " 'dance': 3605,\n",
       " 'class': 2679,\n",
       " 'cheerobix': 2539,\n",
       " 'work': 15183,\n",
       " 'really': 10965,\n",
       " 'lot': 8178,\n",
       " 'support': 13345,\n",
       " 'lacking': 7737,\n",
       " 'worn': 15206,\n",
       " 'times': 13893,\n",
       " 'imagine': 6912,\n",
       " 'once': 9454,\n",
       " 'won': 15161,\n",
       " 'bother': 1879,\n",
       " 'ankle': 902,\n",
       " 'bit': 1697,\n",
       " 'rubbing': 11672,\n",
       " 'deter': 3935,\n",
       " 'wearing': 14949,\n",
       " '10': 19,\n",
       " 'wide': 15067,\n",
       " 'feet': 5287,\n",
       " 'thinking': 13780,\n",
       " 'two': 14296,\n",
       " 'thumbs': 13848,\n",
       " 'cute': 3560,\n",
       " 'do': 4219,\n",
       " 'job': 7494,\n",
       " 'rah': 10849,\n",
       " 'book': 1840,\n",
       " 'fills': 5350,\n",
       " 'missing': 8756,\n",
       " 'pages': 9703,\n",
       " 'street': 13115,\n",
       " 'history': 6624,\n",
       " 'documents': 4235,\n",
       " 'african': 649,\n",
       " 'americans': 830,\n",
       " 'overcame': 9633,\n",
       " 'racism': 10833,\n",
       " 'barriers': 1425,\n",
       " 'become': 1520,\n",
       " 'successful': 13257,\n",
       " 'financial': 5365,\n",
       " 'securities': 12010,\n",
       " 'industry': 7050,\n",
       " 'should': 12281,\n",
       " 'part': 9788,\n",
       " 'every': 4927,\n",
       " 'business': 2141,\n",
       " 'curriculum': 3538,\n",
       " 'first': 5398,\n",
       " 'best': 1618,\n",
       " 'its': 7396,\n",
       " 'kind': 7642,\n",
       " 'no': 9211,\n",
       " 'stars': 12943,\n",
       " 'screen': 11925,\n",
       " 'comes': 2884,\n",
       " 'tap': 13542,\n",
       " 'caption': 2282,\n",
       " 'changes': 2474,\n",
       " 'huh': 6765,\n",
       " 'been': 1533,\n",
       " 'coleman': 2829,\n",
       " 'stoves': 13077,\n",
       " 'until': 14518,\n",
       " 'previous': 10468,\n",
       " 'reviewer': 11440,\n",
       " 'posted': 10318,\n",
       " 'shoddy': 12253,\n",
       " 'construction': 3149,\n",
       " 'ultra': 14328,\n",
       " 'low': 8211,\n",
       " 'sheet': 12206,\n",
       " 'metal': 8628,\n",
       " 'combine': 2869,\n",
       " 'create': 3404,\n",
       " 'ready': 10950,\n",
       " 'rid': 11491,\n",
       " 'edges': 4535,\n",
       " 'sharp': 12187,\n",
       " 'latch': 7798,\n",
       " 'due': 4428,\n",
       " 'engineering': 4733,\n",
       " 'manufacturing': 8386,\n",
       " 'issue': 7372,\n",
       " 'bottom': 1886,\n",
       " 'green': 6158,\n",
       " 'piece': 10079,\n",
       " 'fit': 5405,\n",
       " 'properly': 10611,\n",
       " 'into': 7275,\n",
       " 'silver': 12362,\n",
       " 'lip': 8044,\n",
       " 'currently': 3537,\n",
       " 'replacement': 11285,\n",
       " 'stove': 13075,\n",
       " 'horribly': 6709,\n",
       " 'made': 8280,\n",
       " 'said': 11737,\n",
       " 'cook': 3241,\n",
       " 'pretty': 10458,\n",
       " 'without': 15142,\n",
       " 'crushed': 3480,\n",
       " 'car': 2290,\n",
       " 'ride': 11494,\n",
       " 'camp': 2224,\n",
       " 'site': 12425,\n",
       " 'point': 10221,\n",
       " 'cruddy': 3473,\n",
       " 'outweighs': 9625,\n",
       " 'functionality': 5769,\n",
       " 'spend': 12791,\n",
       " '15': 59,\n",
       " 'min': 8691,\n",
       " 'each': 4467,\n",
       " 'app': 973,\n",
       " 'daughter': 3641,\n",
       " '38': 233,\n",
       " 'having': 6415,\n",
       " 'fun': 5766,\n",
       " 'hope': 6695,\n",
       " 'bought': 1888,\n",
       " 'inside': 7144,\n",
       " 'kept': 7611,\n",
       " 'occupied': 9384,\n",
       " 'hours': 6736,\n",
       " 'year': 15286,\n",
       " 'grandmother': 6117,\n",
       " 'has': 6390,\n",
       " 'searching': 11977,\n",
       " 'high': 6575,\n",
       " 'fashion': 5229,\n",
       " 'cotton': 3317,\n",
       " 'bra': 1917,\n",
       " 'elastic': 4591,\n",
       " 'bras': 1941,\n",
       " 'chap': 2481,\n",
       " 'skin': 12458,\n",
       " 'directly': 4059,\n",
       " 'touching': 14007,\n",
       " 'louisiana': 8192,\n",
       " 'california': 2199,\n",
       " 'loves': 8207,\n",
       " 'sisters': 12423,\n",
       " 'asking': 1119,\n",
       " 'place': 10129,\n",
       " 'orders': 9539,\n",
       " 'tested': 13687,\n",
       " 'doubts': 4293,\n",
       " 'exceed': 4967,\n",
       " 'expectations': 5032,\n",
       " 'since': 12395,\n",
       " 'seen': 12025,\n",
       " 'people': 9919,\n",
       " 'exquisite': 5099,\n",
       " 'thanks': 13715,\n",
       " 'amazon': 815,\n",
       " 'yes': 15296,\n",
       " 'lookin': 8153,\n",
       " 'sexy': 12149,\n",
       " 'may': 8496,\n",
       " 'small': 12535,\n",
       " 'protect': 10629,\n",
       " 'underneath': 14388,\n",
       " 'front': 5731,\n",
       " 'seats': 11986,\n",
       " 'expensive': 5040,\n",
       " 'custom': 3550,\n",
       " 'ask': 1117,\n",
       " 'both': 1878,\n",
       " 'back': 1325,\n",
       " 'together': 13933,\n",
       " 'must': 8981,\n",
       " 'admit': 583,\n",
       " 'albums': 730,\n",
       " 'download': 4302,\n",
       " '18': 78,\n",
       " '06': 6,\n",
       " 'passion': 9813,\n",
       " 'play': 10170,\n",
       " 'tull': 14238,\n",
       " 'album': 729,\n",
       " 'keep': 7592,\n",
       " 'complete': 2970,\n",
       " 'collection': 2839,\n",
       " 'fact': 5155,\n",
       " 'shuffled': 12311,\n",
       " 'retirement': 11411,\n",
       " 'projects': 10581,\n",
       " 'digitize': 4026,\n",
       " 'tapes': 13546,\n",
       " 'less': 7934,\n",
       " 'music': 8970,\n",
       " 'recording': 11050,\n",
       " 'purists': 10727,\n",
       " 'prefer': 10404,\n",
       " 'vinyl': 14740,\n",
       " 'which': 15025,\n",
       " 'moments': 8823,\n",
       " 'notice': 9263,\n",
       " 'while': 15028,\n",
       " 'star': 12933,\n",
       " 'nothing': 9262,\n",
       " 'seeing': 12017,\n",
       " 'jt': 7525,\n",
       " 'ian': 6831,\n",
       " 'concert': 3028,\n",
       " 'sure': 13359,\n",
       " 'check': 2528,\n",
       " 'performing': 9947,\n",
       " 'taab': 13475,\n",
       " 'taab2': 13476,\n",
       " 'sf': 12150,\n",
       " 'july': 7543,\n",
       " 'dawgjethro': 3650,\n",
       " 'set': 12115,\n",
       " 'favorite': 5256,\n",
       " 'television': 13623,\n",
       " 'time': 13884,\n",
       " 'second': 11992,\n",
       " 'wire': 15116,\n",
       " 'although': 791,\n",
       " 'yorker': 15306,\n",
       " 'related': 11165,\n",
       " 'dealt': 3679,\n",
       " 'denis': 3828,\n",
       " 'franz': 5667,\n",
       " 'character': 2484,\n",
       " 'andy': 883,\n",
       " 'miss': 8751,\n",
       " 'off': 9404,\n",
       " 'characters': 2488,\n",
       " 'week': 14966,\n",
       " 'whenever': 15016,\n",
       " 'reason': 10974,\n",
       " 'got': 6066,\n",
       " 'prime': 10485,\n",
       " 'needed': 9102,\n",
       " 'norton': 9242,\n",
       " '360': 230,\n",
       " 'ordered': 9537,\n",
       " 'however': 6747,\n",
       " 'went': 14992,\n",
       " 'install': 7168,\n",
       " 'message': 8622,\n",
       " 'replace': 11282,\n",
       " 'newer': 9158,\n",
       " 'version': 14694,\n",
       " 'already': 778,\n",
       " 'computer': 3005,\n",
       " 'windows': 15099,\n",
       " 'hp': 6750,\n",
       " 'trial': 14139,\n",
       " 'stuck': 13170,\n",
       " 'spent': 12795,\n",
       " 'loaded': 8092,\n",
       " 'cannot': 2256,\n",
       " 'cancel': 2238,\n",
       " 'return': 11419,\n",
       " 'downloaded': 4303,\n",
       " 'apparently': 979,\n",
       " 'current': 3536,\n",
       " 'drawing': 4341,\n",
       " 'im': 6900,\n",
       " 'wasnt': 14904,\n",
       " 'draw': 4334,\n",
       " 'boss': 1874,\n",
       " 'wish': 15126,\n",
       " 'unlocked': 14466,\n",
       " 'witout': 15148,\n",
       " 'pay': 9866,\n",
       " 'themcool': 13738,\n",
       " 'though': 13802,\n",
       " 'saw': 11821,\n",
       " 'episodes': 4811,\n",
       " 'years': 15288,\n",
       " 'ago': 679,\n",
       " 'seems': 12024,\n",
       " 'nostalgia': 9250,\n",
       " 'especially': 4861,\n",
       " 'via': 14705,\n",
       " 'tv': 14268,\n",
       " 'memories': 8587,\n",
       " 'regardless': 11117,\n",
       " 'politics': 10250,\n",
       " 'faith': 5178,\n",
       " 'system': 13468,\n",
       " 'read': 10936,\n",
       " 'divisive': 4212,\n",
       " 'learn': 7873,\n",
       " 'civil': 2663,\n",
       " 'dialogs': 3980,\n",
       " 'midst': 8666,\n",
       " 'competing': 2955,\n",
       " 'views': 14728,\n",
       " 'tear': 13591,\n",
       " 'another': 924,\n",
       " 'apart': 957,\n",
       " 'slaughter': 12476,\n",
       " 'et': 4886,\n",
       " 'al': 721,\n",
       " 'call': 2201,\n",
       " 'sit': 12424,\n",
       " 'table': 13478,\n",
       " 'discuss': 4132,\n",
       " 'implications': 6945,\n",
       " 'policy': 10242,\n",
       " 'political': 10247,\n",
       " 'season': 11980,\n",
       " 'started': 12947,\n",
       " 'hobby': 6637,\n",
       " 'career': 2307,\n",
       " 'designer': 3895,\n",
       " 'struggling': 13166,\n",
       " 'getting': 5923,\n",
       " 'organized': 9548,\n",
       " 'knowing': 7692,\n",
       " 'start': 12946,\n",
       " 'includes': 6991,\n",
       " 'essentials': 4872,\n",
       " 'basics': 1444,\n",
       " 'design': 3893,\n",
       " 'checked': 2529,\n",
       " 'library': 7962,\n",
       " 'after': 651,\n",
       " 'reading': 10946,\n",
       " 'cover': 3353,\n",
       " 'decided': 3707,\n",
       " 'own': 9669,\n",
       " 'copy': 3272,\n",
       " 'highly': 6582,\n",
       " 'designers': 3896,\n",
       " 'picture': 10076,\n",
       " 'adjusted': 570,\n",
       " 'sound': 12712,\n",
       " 'folding': 5543,\n",
       " 'makes': 8329,\n",
       " 'compact': 2930,\n",
       " 'antenna': 929,\n",
       " 'strap': 13095,\n",
       " 'works': 15196,\n",
       " 'position': 10299,\n",
       " 'yourself': 15320,\n",
       " 'reception': 11005,\n",
       " 'calendar': 2196,\n",
       " 'books': 1845,\n",
       " 'illustrations': 6898,\n",
       " 'wonderful': 15164,\n",
       " 'daily': 3587,\n",
       " 'reminder': 11229,\n",
       " 'fabulous': 5139,\n",
       " 'drawings': 4342,\n",
       " 'chef': 2544,\n",
       " 'home': 6663,\n",
       " 'kids': 7632,\n",
       " 'who': 15053,\n",
       " 'growing': 6213,\n",
       " 'cooking': 3245,\n",
       " 'kitchen': 7665,\n",
       " 'bait': 1362,\n",
       " 'bar': 1409,\n",
       " 'multiple': 8949,\n",
       " 'rats': 10904,\n",
       " 'our': 9580,\n",
       " 'compost': 2993,\n",
       " 'pile': 10085,\n",
       " 'within': 15138,\n",
       " 'gone': 6043,\n",
       " 'found': 5629,\n",
       " 'dead': 3667,\n",
       " '34': 223,\n",
       " 'controversial': 3215,\n",
       " 'aired': 706,\n",
       " 'little': 8074,\n",
       " 'nudity': 9306,\n",
       " 'episode': 4810,\n",
       " 'gritty': 6191,\n",
       " 'moving': 8913,\n",
       " 'story': 13068,\n",
       " 'experience': 5042,\n",
       " 'private': 10507,\n",
       " 'lives': 8080,\n",
       " 'broke': 2023,\n",
       " 'ice': 6835,\n",
       " 'dennis': 3829,\n",
       " 'whole': 15055,\n",
       " 'cop': 3261,\n",
       " 'nypd': 9336,\n",
       " 'blue': 1773,\n",
       " 'expert': 5052,\n",
       " 'creating': 3407,\n",
       " 'designs': 3899,\n",
       " 'guide': 6232,\n",
       " 'feel': 5281,\n",
       " 'things': 13776,\n",
       " 'useful': 14572,\n",
       " 'listening': 8059,\n",
       " 'zia': 15349,\n",
       " 'mohiuddin': 8806,\n",
       " 'dagar': 3585,\n",
       " 'rudra': 11677,\n",
       " 'veena': 14656,\n",
       " 'watching': 14917,\n",
       " 'night': 9185,\n",
       " 'contemplate': 3170,\n",
       " 'ways': 14936,\n",
       " 'move': 8904,\n",
       " 'relation': 11168,\n",
       " 'understand': 14393,\n",
       " 'imaginatively': 6911,\n",
       " 'creates': 3406,\n",
       " 'precise': 10386,\n",
       " 'relationships': 11172,\n",
       " 'between': 1630,\n",
       " 'tones': 13954,\n",
       " 'plays': 10181,\n",
       " 'heavenly': 6490,\n",
       " 'spheres': 12797,\n",
       " 'called': 2203,\n",
       " 'henry': 6540,\n",
       " 'probably': 10516,\n",
       " 'far': 5217,\n",
       " 'accurate': 471,\n",
       " 'portrayal': 10292,\n",
       " 'ireland': 7337,\n",
       " 'british': 2012,\n",
       " 'rule': 11683,\n",
       " 'realise': 10954,\n",
       " 'activities': 522,\n",
       " 'members': 8582,\n",
       " 'michael': 8649,\n",
       " 'collins': 2845,\n",
       " 'quot': 10816,\n",
       " 'squad': 12881,\n",
       " 'performed': 9944,\n",
       " 'smart': 12541,\n",
       " 'novel': 9277,\n",
       " 'periphery': 9956,\n",
       " 'possibly': 10314,\n",
       " 'most': 8871,\n",
       " 'effective': 4560,\n",
       " 'counter': 3329,\n",
       " 'intellegence': 7204,\n",
       " 'agency': 669,\n",
       " 'world': 15200,\n",
       " 'roddy': 11584,\n",
       " 'doyle': 4314,\n",
       " 'excellent': 4973,\n",
       " 'captures': 2288,\n",
       " 'anything': 950,\n",
       " 'hitherto': 6626,\n",
       " 'subject': 13216,\n",
       " 'feeling': 5283,\n",
       " 'dubliners': 4425,\n",
       " 'towards': 14013,\n",
       " 'easter': 4504,\n",
       " 'rising': 11534,\n",
       " 'executions': 4996,\n",
       " 'attitude': 1206,\n",
       " 'beyond': 1636,\n",
       " 'pale': 9722,\n",
       " 'controlled': 3208,\n",
       " 'region': 11123,\n",
       " 'dublin': 4423,\n",
       " 'phrase': 10055,\n",
       " 'jackeens': 7409,\n",
       " 'delay': 3781,\n",
       " 'leaving': 7885,\n",
       " 'believe': 1574,\n",
       " 'surprising': 13377,\n",
       " 'seem': 12020,\n",
       " 'think': 13778,\n",
       " 'loyalty': 8221,\n",
       " 'similar': 12366,\n",
       " 'his': 6614,\n",
       " 'feelings': 5284,\n",
       " 'james': 7429,\n",
       " 'connolly': 3108,\n",
       " 'debt': 3694,\n",
       " 'honour': 6683,\n",
       " 'him': 6598,\n",
       " 'abandoning': 382,\n",
       " 'unresolved': 14496,\n",
       " 'betrayal': 1624,\n",
       " 'death': 3685,\n",
       " 'free': 5676,\n",
       " 'country': 3336,\n",
       " 'attributes': 1217,\n",
       " 'visible': 14756,\n",
       " 'major': 8323,\n",
       " 'influence': 7079,\n",
       " 'actions': 512,\n",
       " 'various': 14643,\n",
       " 'loyalties': 8220,\n",
       " 'strong': 13154,\n",
       " 'force': 5572,\n",
       " 'wasn': 14903,\n",
       " 'author': 1243,\n",
       " 'preferring': 10409,\n",
       " 'film': 5351,\n",
       " 'versions': 14695,\n",
       " 'barrytown': 1430,\n",
       " 'trilogy': 14158,\n",
       " 'await': 1274,\n",
       " 'anticipation': 940,\n",
       " 'remaining': 11209,\n",
       " 'latest': 7805,\n",
       " 'finest': 5374,\n",
       " 'hour': 6735,\n",
       " 'charlie': 2500,\n",
       " 'sheen': 12204,\n",
       " 'bowling': 1905,\n",
       " 'decent': 3704,\n",
       " 'problems': 10518,\n",
       " 'seasons': 11983,\n",
       " 'groundbreaking': 6203,\n",
       " 'watch': 14910,\n",
       " 'again': 660,\n",
       " 'appearances': 984,\n",
       " 'number': 9310,\n",
       " 'faces': 5144,\n",
       " 'classic': 2683,\n",
       " 'didn': 3997,\n",
       " 'smits': 12559,\n",
       " 'joined': 7505,\n",
       " 'loved': 8196,\n",
       " 'chance': 2469,\n",
       " 'beginning': 1553,\n",
       " 'planning': 10147,\n",
       " 'entire': 4788,\n",
       " 'excited': 4984,\n",
       " 'grow': 6212,\n",
       " 'compressed': 2999,\n",
       " 'frame': 5648,\n",
       " 'prim': 10482,\n",
       " 'shouldi': 12285,\n",
       " 'uninterrupted': 14441,\n",
       " 'almost': 771,\n",
       " 'forward': 5622,\n",
       " 'retired': 11410,\n",
       " 'robert': 11565,\n",
       " 'hall': 6306,\n",
       " 'us': 14559,\n",
       " 'basic': 1442,\n",
       " 'concepts': 3022,\n",
       " 'protecting': 10632,\n",
       " 'individuals': 7041,\n",
       " 'pitfalls': 10120,\n",
       " 'society': 12620,\n",
       " 'commonsense': 2921,\n",
       " 'devoid': 3960,\n",
       " 'mr': 8922,\n",
       " 'perspective': 9989,\n",
       " 'broad': 2015,\n",
       " 'insight': 7146,\n",
       " 'welcomed': 14982,\n",
       " 'refreshing': 11102,\n",
       " 'change': 2471,\n",
       " 'over': 9627,\n",
       " 'typical': 14305,\n",
       " 'main': 8312,\n",
       " 'stream': 13107,\n",
       " 'self': 12037,\n",
       " 'help': 6525,\n",
       " 'guides': 6235,\n",
       " '12': 38,\n",
       " 'step': 12997,\n",
       " 'programs': 10568,\n",
       " 'focus': 5530,\n",
       " 'personal': 9981,\n",
       " 'safety': 11734,\n",
       " 'reliance': 11189,\n",
       " 'actual': 530,\n",
       " 'prevention': 10464,\n",
       " 'offers': 9412,\n",
       " 'simple': 12379,\n",
       " 'solutions': 12657,\n",
       " 'harm': 6373,\n",
       " 'adding': 551,\n",
       " 'humor': 6786,\n",
       " 'lessons': 7937,\n",
       " 'former': 5607,\n",
       " 'state': 12958,\n",
       " 'senator': 12047,\n",
       " 'veteran': 14699,\n",
       " 'fathers': 5242,\n",
       " 'family': 5196,\n",
       " 'supply': 13343,\n",
       " 'plan': 10140,\n",
       " 'safer': 11733,\n",
       " 'track': 14028,\n",
       " 'prophecy': 10613,\n",
       " 'did': 3995,\n",
       " 'expand': 5023,\n",
       " 'understanding': 14396,\n",
       " 'living': 8082,\n",
       " 'writing': 15245,\n",
       " 'informative': 7087,\n",
       " 'interested': 7228,\n",
       " 'writings': 15246,\n",
       " 'man': 8341,\n",
       " 'listen': 8055,\n",
       " 'song': 12677,\n",
       " 'such': 13262,\n",
       " 'prevalent': 10460,\n",
       " 'viral': 14748,\n",
       " 'pray': 10372,\n",
       " 'hear': 6468,\n",
       " 'beatrice': 1504,\n",
       " 'months': 8851,\n",
       " 'prepare': 10426,\n",
       " 'child': 2568,\n",
       " 'potentially': 10329,\n",
       " 'daunting': 3645,\n",
       " 'task': 13557,\n",
       " 'babysitting': 1320,\n",
       " 'grandpa': 6119,\n",
       " 'cracks': 3374,\n",
       " 'educational': 4550,\n",
       " 'win': 15094,\n",
       " 'winfor': 15105,\n",
       " 'granddaughter': 6108,\n",
       " 'popcorn': 10271,\n",
       " 'seasoning': 11982,\n",
       " 'salt': 11752,\n",
       " 'tastes': 13565,\n",
       " 'white': 15045,\n",
       " 'cheddar': 2532,\n",
       " 'finally': 5363,\n",
       " 'cheese': 2541,\n",
       " 'name': 9019,\n",
       " 'dry': 4407,\n",
       " 'kwikit': 7723,\n",
       " 'wonderfully': 15166,\n",
       " 'quick': 10796,\n",
       " 'drying': 4410,\n",
       " 'coat': 2792,\n",
       " 'done': 4265,\n",
       " 'painting': 9712,\n",
       " 'nails': 9015,\n",
       " 'nail': 9013,\n",
       " 'thin': 13774,\n",
       " 'oily': 9430,\n",
       " 'worry': 15210,\n",
       " 'cuticles': 3562,\n",
       " 'instantly': 7177,\n",
       " ...}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'and', 'the'}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.stop_words_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2687, 15368)\n",
      "2687\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Our Input Data**\n",
    "1. The X matrix\n",
    "2. The vectorizer\n",
    "3. The y vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple NB classifier for binary response variable -- the [documentation](https://scikit-learn.org/stable/modules/naive_bayes.html) is good -- be sure to read it! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "nb = BernoulliNB()\n",
    "nb.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2687\n",
      "[1 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Use the model to predict the value of all records in the training set\n",
    "ypred = nb.predict(X)\n",
    "print(len(ypred))\n",
    "print(ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 2492, 0: 195})\n",
      "Counter({1: 2316, 0: 371})\n"
     ]
    }
   ],
   "source": [
    "# How many \"good\" predicitions are they, and how does that compare to actual y values?\n",
    "from collections import Counter\n",
    "print(Counter(ypred))\n",
    "print(Counter(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Various tools to measure prediction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 101  270]\n",
      " [  94 2222]]\n",
      "0.8645329363602531\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Confusion matrix -- argument order matters -- y is \n",
    "# down the rows because it is first.  Predicted is across the \n",
    "# columns because it is second.\n",
    "\n",
    "print(confusion_matrix(y, nb.predict(X)))\n",
    "print(accuracy_score(y, nb.predict(X)))\n",
    "\n",
    "# Remember, this is training accuracy.  Bad if it's low, meaningless if it's high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick way to split our X and y into training and test pieces for measuring\n",
    "# test accuracy\n",
    "\n",
    "# The random_state argument seeds the random number generator so you get the\n",
    "# same split each time.  Not random, but good for debugging\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(X, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just a method so we can evaluate a classifier easily\n",
    "\n",
    "def eval_test_set(clf, xtrain, ytrain, xtest, ytest):\n",
    "    clf.fit(xtrain, ytrain)\n",
    "    print(confusion_matrix(ytest, clf.predict(xtest)))\n",
    "    print(accuracy_score(ytest, clf.predict(xtest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 11  85]\n",
      " [ 53 523]]\n",
      "0.7946428571428571\n",
      "[[ 24  72]\n",
      " [ 17 559]]\n",
      "0.8675595238095238\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "eval_test_set(BernoulliNB(), xTrain, yTrain, xTest, yTest)\n",
    "eval_test_set(MultinomialNB(), xTrain, yTrain, xTest, yTest)\n",
    "\n",
    "#  Too bad, test accuracy is much worse than training accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross-Fold Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-fold validation -- this is 10-fold, split the X and y into \n",
    "# ten pieces, loop ten times, one for each piece:  train on the other 9, \n",
    "# then test on the 10th.   Average is estimate for test accuracy\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "def cross_validate(clf, x, y):\n",
    "    return cross_val_score(clf, x, y, cv=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_classifier(clf, X, y):\n",
    "    clf.fit(X,y)\n",
    "    print(f\"Results for {clf}\")\n",
    "    print(f\"Cross validation mean accuracy: {cross_validate(clf, X, y)}\")\n",
    "    print(f\"Training accuracy: {accuracy_score(y, clf.predict(X))}\")\n",
    "    print(confusion_matrix(y, clf.predict(X)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8191116906175442\n",
      "0.8801545247739\n",
      "0.8753190367863286\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import ComplementNB\n",
    "print(cross_validate(BernoulliNB(), X, y))\n",
    "print(cross_validate(MultinomialNB(), X, y))\n",
    "print(cross_validate(ComplementNB(), X, y))\n",
    "\n",
    "# This should be a little better than the holdback test accuracy\n",
    "# because we get to use all the test data\n",
    "\n",
    "# This is our baseline accuracy -- can we change preprocessing and/or get \n",
    "# rid of features to improve it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for BernoulliNB()\n",
      "Cross validation mean accuracy: 0.8191116906175442\n",
      "Training accuracy: 0.8645329363602531\n",
      "[[ 101  270]\n",
      " [  94 2222]]\n",
      "\n",
      "Results for MultinomialNB()\n",
      "Cross validation mean accuracy: 0.8801545247739\n",
      "Training accuracy: 0.9594343133606252\n",
      "[[ 279   92]\n",
      " [  17 2299]]\n",
      "\n",
      "Results for ComplementNB()\n",
      "Cross validation mean accuracy: 0.8753190367863286\n",
      "Training accuracy: 0.9616672869371046\n",
      "[[ 308   63]\n",
      " [  40 2276]]\n"
     ]
    }
   ],
   "source": [
    "eval_classifier(BernoulliNB(), X, y)\n",
    "print()\n",
    "eval_classifier(MultinomialNB(), X, y)\n",
    "print()\n",
    "eval_classifier(ComplementNB(), X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Other Options for a Classifier**\n",
    "\n",
    "How do these perform compared to our Naive Bayes baseline?\n",
    "\n",
    "1. Rocchio (nearest centroid)\n",
    "2. Nearest neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for NearestCentroid()\n",
      "Cross validation mean accuracy: 0.7703670310159241\n",
      "Training accuracy: 0.7912169705991813\n",
      "[[ 224  147]\n",
      " [ 414 1902]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestCentroid\n",
    "eval_classifier(NearestCentroid(), X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8626726959995562\n",
      "[[   3  368]\n",
      " [   0 2316]]\n",
      "0.8630442873092669\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "eval_test_set(KNeighborsClassifier(n_neighbors=20), X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes 0.8191116906175442\n",
      "Multinomial Naive Bayes 0.8801545247739\n",
      "Complement Naive Bayes 0.8753190367863286\n",
      "Nearest Centroid 0.7703670310159241\n",
      "Nearest neighbors (20) 0.8626726959995562\n",
      "Nearest neighbors (5) 0.8634189646562727\n",
      "Nearest neighbors (12) 0.864532819175498\n"
     ]
    }
   ],
   "source": [
    "# Here is apples-to-apples comparison of all models we have tried so far\n",
    "\n",
    "print(f\"Bernoulli Naive Bayes {cross_validate(BernoulliNB(), X, y)}\")\n",
    "print(f\"Multinomial Naive Bayes {cross_validate(MultinomialNB(), X, y)}\")\n",
    "print(f\"Complement Naive Bayes {cross_validate(ComplementNB(), X, y)}\")\n",
    "print(f\"Nearest Centroid {cross_validate(NearestCentroid(), X,y)}\")\n",
    "print(f\"Nearest neighbors (20) {cross_validate(KNeighborsClassifier(n_neighbors=20), X, y)}\")\n",
    "print(f\"Nearest neighbors (5) {cross_validate(KNeighborsClassifier(n_neighbors=5), X, y)}\")\n",
    "print(f\"Nearest neighbors (12) {cross_validate(KNeighborsClassifier(n_neighbors=12), X, y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tentative decision:  choose Multinomial Naive Bayes, reject Rocchio, and experiment to see how much we can improve KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameter Optimization**\n",
    "\n",
    "Nearest Neighbor is the only algorithm with a hyperparameter (number of neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': range(1, 50, 2)}, scoring='accuracy')"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Loop over number of neighbors, and compute cross-validated accuracy for each setting.\n",
    "# Remember the parameter setting with the best accuracy.\n",
    "# Notice that the result of GridSearchCV is also a classifier -- it has fit and predict methods\n",
    "\n",
    "clf = GridSearchCV(KNeighborsClassifier(), {'n_neighbors': range(1,50,2)}, cv=10, scoring='accuracy')\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=7)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notice that the grid search is actually a classifier too!\n",
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00329578, 0.00300138, 0.0030009 , 0.00299962, 0.00299628,\n",
       "        0.00279992, 0.00299091, 0.00280063, 0.00260286, 0.00280509,\n",
       "        0.00260177, 0.00299494, 0.00279799, 0.00289862, 0.00249946,\n",
       "        0.00289602, 0.00290368, 0.0026973 , 0.00269883, 0.00249856,\n",
       "        0.00289543, 0.00289505, 0.0027986 , 0.00298822, 0.00290251]),\n",
       " 'std_fit_time': array([6.43995665e-04, 4.55311976e-04, 6.31846580e-04, 2.96455072e-06,\n",
       "        1.09791950e-05, 3.91409960e-04, 4.38450429e-04, 4.01408873e-04,\n",
       "        4.94851471e-04, 4.02641734e-04, 4.83352439e-04, 1.15916799e-05,\n",
       "        3.98923377e-04, 2.99287272e-04, 5.00040570e-04, 2.99403614e-04,\n",
       "        3.01467890e-04, 4.56192816e-04, 4.49022048e-04, 4.98944674e-04,\n",
       "        5.36799535e-04, 5.31200447e-04, 3.99294960e-04, 4.40899315e-04,\n",
       "        3.01209375e-04]),\n",
       " 'mean_score_time': array([0.04321139, 0.04269962, 0.04611547, 0.04379902, 0.04471042,\n",
       "        0.04399917, 0.04360812, 0.04421372, 0.04439709, 0.04409671,\n",
       "        0.0447084 , 0.04350302, 0.04389455, 0.04460011, 0.04449942,\n",
       "        0.04401281, 0.04409738, 0.0441051 , 0.04419875, 0.04461715,\n",
       "        0.04460564, 0.04509985, 0.04451993, 0.04481344, 0.04471433]),\n",
       " 'std_score_time': array([0.00315319, 0.00237081, 0.00241071, 0.00098044, 0.00224496,\n",
       "        0.00126616, 0.00080692, 0.00125802, 0.00128169, 0.00093761,\n",
       "        0.00100541, 0.00067275, 0.00094342, 0.00126565, 0.00093059,\n",
       "        0.00078414, 0.00104676, 0.00113256, 0.00087934, 0.00064302,\n",
       "        0.00080747, 0.00082757, 0.00140385, 0.00074566, 0.00120091]),\n",
       " 'param_n_neighbors': masked_array(data=[1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29,\n",
       "                    31, 33, 35, 37, 39, 41, 43, 45, 47, 49],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'n_neighbors': 1},\n",
       "  {'n_neighbors': 3},\n",
       "  {'n_neighbors': 5},\n",
       "  {'n_neighbors': 7},\n",
       "  {'n_neighbors': 9},\n",
       "  {'n_neighbors': 11},\n",
       "  {'n_neighbors': 13},\n",
       "  {'n_neighbors': 15},\n",
       "  {'n_neighbors': 17},\n",
       "  {'n_neighbors': 19},\n",
       "  {'n_neighbors': 21},\n",
       "  {'n_neighbors': 23},\n",
       "  {'n_neighbors': 25},\n",
       "  {'n_neighbors': 27},\n",
       "  {'n_neighbors': 29},\n",
       "  {'n_neighbors': 31},\n",
       "  {'n_neighbors': 33},\n",
       "  {'n_neighbors': 35},\n",
       "  {'n_neighbors': 37},\n",
       "  {'n_neighbors': 39},\n",
       "  {'n_neighbors': 41},\n",
       "  {'n_neighbors': 43},\n",
       "  {'n_neighbors': 45},\n",
       "  {'n_neighbors': 47},\n",
       "  {'n_neighbors': 49}],\n",
       " 'split0_test_score': array([0.86245353, 0.86245353, 0.86245353, 0.866171  , 0.866171  ,\n",
       "        0.866171  , 0.866171  , 0.866171  , 0.866171  , 0.86245353,\n",
       "        0.86245353, 0.86245353, 0.86245353, 0.86245353, 0.86245353,\n",
       "        0.86245353, 0.86245353, 0.86245353, 0.86245353, 0.86245353,\n",
       "        0.86245353, 0.86245353, 0.86245353, 0.86245353, 0.86245353]),\n",
       " 'split1_test_score': array([0.8401487 , 0.84386617, 0.85501859, 0.86245353, 0.86245353,\n",
       "        0.86245353, 0.86245353, 0.86245353, 0.86245353, 0.86245353,\n",
       "        0.86245353, 0.86245353, 0.86245353, 0.86245353, 0.86245353,\n",
       "        0.86245353, 0.86245353, 0.86245353, 0.86245353, 0.86245353,\n",
       "        0.86245353, 0.86245353, 0.86245353, 0.86245353, 0.86245353]),\n",
       " 'split2_test_score': array([0.83271375, 0.86988848, 0.86245353, 0.86988848, 0.86245353,\n",
       "        0.86245353, 0.86245353, 0.86245353, 0.86245353, 0.86245353,\n",
       "        0.86245353, 0.86245353, 0.86245353, 0.86245353, 0.86245353,\n",
       "        0.86245353, 0.86245353, 0.86245353, 0.86245353, 0.86245353,\n",
       "        0.86245353, 0.86245353, 0.86245353, 0.86245353, 0.86245353]),\n",
       " 'split3_test_score': array([0.85873606, 0.86245353, 0.85873606, 0.86245353, 0.86988848,\n",
       "        0.866171  , 0.86245353, 0.86245353, 0.86245353, 0.86245353,\n",
       "        0.86245353, 0.86245353, 0.86245353, 0.86245353, 0.86245353,\n",
       "        0.86245353, 0.86245353, 0.86245353, 0.86245353, 0.86245353,\n",
       "        0.86245353, 0.86245353, 0.86245353, 0.86245353, 0.86245353]),\n",
       " 'split4_test_score': array([0.80297398, 0.87360595, 0.86988848, 0.866171  , 0.86245353,\n",
       "        0.86245353, 0.86245353, 0.86245353, 0.86245353, 0.86245353,\n",
       "        0.86245353, 0.86245353, 0.86245353, 0.86245353, 0.86245353,\n",
       "        0.86245353, 0.86245353, 0.86245353, 0.86245353, 0.86245353,\n",
       "        0.86245353, 0.86245353, 0.86245353, 0.86245353, 0.86245353]),\n",
       " 'split5_test_score': array([0.85501859, 0.85873606, 0.86988848, 0.87360595, 0.866171  ,\n",
       "        0.86245353, 0.86245353, 0.86245353, 0.86245353, 0.866171  ,\n",
       "        0.86245353, 0.86245353, 0.86245353, 0.86245353, 0.86245353,\n",
       "        0.86245353, 0.86245353, 0.86245353, 0.86245353, 0.86245353,\n",
       "        0.86245353, 0.86245353, 0.86245353, 0.86245353, 0.86245353]),\n",
       " 'split6_test_score': array([0.84758364, 0.85130112, 0.85873606, 0.86245353, 0.86245353,\n",
       "        0.86245353, 0.86245353, 0.85873606, 0.85873606, 0.85873606,\n",
       "        0.85873606, 0.85873606, 0.85873606, 0.85873606, 0.85873606,\n",
       "        0.85873606, 0.85873606, 0.85873606, 0.85873606, 0.85873606,\n",
       "        0.85873606, 0.85873606, 0.85873606, 0.85873606, 0.85873606]),\n",
       " 'split7_test_score': array([0.83208955, 0.85820896, 0.86567164, 0.8619403 , 0.86567164,\n",
       "        0.8619403 , 0.86567164, 0.86567164, 0.8619403 , 0.8619403 ,\n",
       "        0.8619403 , 0.8619403 , 0.8619403 , 0.8619403 , 0.8619403 ,\n",
       "        0.8619403 , 0.8619403 , 0.8619403 , 0.8619403 , 0.8619403 ,\n",
       "        0.8619403 , 0.8619403 , 0.8619403 , 0.8619403 , 0.8619403 ]),\n",
       " 'split8_test_score': array([0.84701493, 0.85447761, 0.86940299, 0.86940299, 0.86940299,\n",
       "        0.86567164, 0.86567164, 0.86567164, 0.8619403 , 0.8619403 ,\n",
       "        0.86567164, 0.8619403 , 0.8619403 , 0.8619403 , 0.8619403 ,\n",
       "        0.8619403 , 0.8619403 , 0.8619403 , 0.8619403 , 0.8619403 ,\n",
       "        0.8619403 , 0.8619403 , 0.8619403 , 0.8619403 , 0.8619403 ]),\n",
       " 'split9_test_score': array([0.84328358, 0.85447761, 0.8619403 , 0.8619403 , 0.8619403 ,\n",
       "        0.8619403 , 0.8619403 , 0.8619403 , 0.8619403 , 0.8619403 ,\n",
       "        0.8619403 , 0.8619403 , 0.8619403 , 0.8619403 , 0.8619403 ,\n",
       "        0.8619403 , 0.8619403 , 0.8619403 , 0.8619403 , 0.8619403 ,\n",
       "        0.8619403 , 0.8619403 , 0.8619403 , 0.8619403 , 0.8619403 ]),\n",
       " 'mean_test_score': array([0.84220163, 0.8589469 , 0.86341896, 0.86564806, 0.86490595,\n",
       "        0.86341619, 0.86341758, 0.86304583, 0.86229956, 0.86229956,\n",
       "        0.86230095, 0.86192781, 0.86192781, 0.86192781, 0.86192781,\n",
       "        0.86192781, 0.86192781, 0.86192781, 0.86192781, 0.86192781,\n",
       "        0.86192781, 0.86192781, 0.86192781, 0.86192781, 0.86192781]),\n",
       " 'std_test_score': array([0.016237  , 0.00828024, 0.0049302 , 0.00392512, 0.00285812,\n",
       "        0.00171041, 0.00159692, 0.00212384, 0.00167906, 0.00167906,\n",
       "        0.00156428, 0.0010884 , 0.0010884 , 0.0010884 , 0.0010884 ,\n",
       "        0.0010884 , 0.0010884 , 0.0010884 , 0.0010884 , 0.0010884 ,\n",
       "        0.0010884 , 0.0010884 , 0.0010884 , 0.0010884 , 0.0010884 ]),\n",
       " 'rank_test_score': array([25, 24,  3,  1,  2,  5,  4,  6,  8,  8,  7, 10, 10, 10, 10, 10, 10,\n",
       "        10, 10, 10, 10, 10, 10, 10, 10])}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest neighbors (5) 0.8649059535038562\n"
     ]
    }
   ],
   "source": [
    "# Just for completeness, this is optimal accuracy for KNN.\n",
    "print(f\"Nearest neighbors (optimal) {cross_validate(clf, X, y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  There is an interesting curve relating number of neighbors to accuracy\n",
    "#  This piece just collects (x,y) pairs where x is neighbors and y is accuracy,\n",
    "#   so we can do a plot\n",
    "\n",
    "neighbors = []\n",
    "accuracies = []\n",
    "\n",
    "for nn in range(1,100,2):\n",
    "    neighbors.append(nn)\n",
    "    accuracies.append(cross_validate(KNeighborsClassifier(n_neighbors=nn), X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# (x,y) line plot of number of neighbors vs test accuracy\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "ax.plot(neighbors, accuracies);\n",
    "ax.set_xlabel('# Neighbors')\n",
    "ax.set_ylabel(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8619278005210271"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What value is the accuracy converging to?\n",
    "Counter(y)[1]/ (Counter(y)[0]+Counter(y)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------\n",
    "### Feature Engineering\n",
    "\n",
    "Improve the algorithm by modifying the vectorizer, limiting features\n",
    "\n",
    "This all starts with the assumption that we will go with Naive Bayes as our classifier of choice\n",
    "\n",
    "1.  See if we can improve the tokenizer -- TFIDF\n",
    "  1. We could try n-grams and stop words too, because the Vectorizer can do those for us\n",
    "2.  See if we can limit features -- do it in the Vectorizer, and also try some more informed greedy methods like mutual information\n",
    "3.  Examine the misclassifications to see if there's anything obviously wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Variations on the vectorizer -- try just Count vs Tfidf\n",
    "* Other variants would be stemming, n-grams, stop words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectorizer 0.8797841646784663\n",
      "Tfidf Vectorizer 0.8615560672474061\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "b = MultinomialNB()\n",
    "\n",
    "v = CountVectorizer()\n",
    "X = v.fit_transform(reviews.text)\n",
    "print(f\"Count Vectorizer {cross_validate(b, X, y)}\")\n",
    "\n",
    "v = TfidfVectorizer()\n",
    "X = v.fit_transform(reviews.text)\n",
    "print(f\"Tfidf Vectorizer {cross_validate(b, X, y)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectorizer 0.8812780891083614\n"
     ]
    }
   ],
   "source": [
    "# Try restricting out uncommon and super common words\n",
    "v = CountVectorizer(min_df=2, max_df=.95)\n",
    "X = v.fit_transform(reviews.text)\n",
    "print(f\"Count Vectorizer {cross_validate(b, X, y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectorizer 0.9017560894412695\n"
     ]
    }
   ],
   "source": [
    "# Try bigrams\n",
    "v = CountVectorizer(min_df=2, max_df=.95, ngram_range=(1,2))\n",
    "X = v.fit_transform(reviews.text)\n",
    "print(f\"Count Vectorizer {cross_validate(b, X, y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2687, 27938)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection by Mutual Information\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature selection by mutual information measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00031059, 0.00022137, 0.00011064, ..., 0.00038763, 0.00011064,\n",
       "       0.00011064])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "# https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection\n",
    "mutual_info_classif(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2687, 100)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select K best\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "newX = SelectKBest(mutual_info_classif, k=100).fit_transform(X,y)\n",
    "newX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_features_x(k, X, y, fs=mutual_info_classif):\n",
    "    kbest = SelectKBest(fs, k=k)\n",
    "    return kbest.fit_transform(X, y)\n",
    "\n",
    "#  Assess accuracy of the classifier after choosing k best features\n",
    "def k_features_accuracy(k, clf, x, y, fs=mutual_info_classif):\n",
    "    X_new = k_features_x(k, x, y, fs)\n",
    "    return cross_validate(clf, X_new, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9419533374022082"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = CountVectorizer(min_df=2, max_df=.95, ngram_range=(1,2)).fit_transform(reviews.text)\n",
    "k_features_accuracy(5000, MultinomialNB(), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "# Caution!!  This takes a very long time!\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "v = CountVectorizer(min_df=2, max_df=.95, ngram_range=(1,2))\n",
    "X = v.fit_transform(reviews.text)\n",
    "\n",
    "#  Set up to plot accuracy as a function of k (number features)\n",
    "xval = []\n",
    "yval = []\n",
    "for k in range(100, 4000, 400):\n",
    "    print(k)\n",
    "    xval.append(k)\n",
    "    yval.append(k_features_accuracy(k, mnb, X, y))\n",
    "for k in range(4000, X.shape[1], 500):\n",
    "    print(k)\n",
    "    xval.append(k)\n",
    "    yval.append(k_features_accuracy(k, mnb, X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "import numpy as np\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "ax.plot(xval, yval);\n",
    "\n",
    "# Nice plot with optimal number of features around 3000 (out of 14.8K!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample plot of cross-val accuracy vs number of features\n",
    "\n",
    "![Accuracy vs num features](accuracy_vs_num_features.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier-Specific Feature Impact\n",
    "\n",
    "Since we are using Naive Bayes, the classifier itself has a measure of feature impact, through the ratio of P(term|class=0) / P(term|class=1).\n",
    "\n",
    "In that ratio, the highest value are the terms that are \"most negative\" and the lowest values are the terms that are \"most positive\" and a value of 1 means the term is irrelevant.   \n",
    "\n",
    "This code shows the features that have the highest and lowest ratio.\n",
    "\n",
    "The question is whether this measure is better than mutual information for limiting # features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -9.10841838, -10.49471274,  -9.39610045, ..., -10.49471274,\n",
       "        -10.49471274, -10.49471274],\n",
       "       [ -9.68440959, -10.29054539, -11.38915768, ..., -10.47286695,\n",
       "        -10.98369257,  -9.30971614]])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = CountVectorizer(min_df=2, max_df=.95)\n",
    "X = v.fit_transform(reviews.text)\n",
    "b = MultinomialNB()\n",
    "b.fit(X, y)\n",
    "\n",
    "#v.get_feature_names()\n",
    "b.feature_log_prob_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_prob_ratios(classifier):\n",
    "    return classifier.feature_log_prob_[0] / classifier.feature_log_prob_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.3820346192536608,\n",
       " 1.3743822770074574,\n",
       " 1.3585415756550019,\n",
       " 1.3445040295876998,\n",
       " 1.3420992392390403,\n",
       " 1.3342531418730963,\n",
       " 1.3256840649867863,\n",
       " 1.3126229923130972,\n",
       " 1.3012509898392406,\n",
       " 1.2966869892539765]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(log_prob_ratios(b)), reverse=True)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def important_features(vectorizer,classifier,n=20):\n",
    "    feature_names =vectorizer.get_feature_names()\n",
    "    log_prob_frac = log_prob_ratios(classifier)\n",
    "    frac_and_name_pos = sorted(zip(log_prob_frac, feature_names),reverse=True)[:n]\n",
    "    frac_and_name_neg = sorted(zip(log_prob_frac, feature_names),reverse=False)[:n]   \n",
    "    print(f\"Important words POSITIVE\")\n",
    "    for coef, feat in frac_and_name_pos:\n",
    "        print(coef, feat)\n",
    "    print(\"==========\")\n",
    "    print(f\"Important words NEGATIVE\")\n",
    "    for coef, feat in frac_and_name_neg:\n",
    "        print(coef, feat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Important words POSITIVE\n",
      "1.3820346192536608 enjoyed\n",
      "1.3743822770074574 love\n",
      "1.3585415756550019 season\n",
      "1.3445040295876998 stories\n",
      "1.3420992392390403 drama\n",
      "1.3342531418730963 nypd\n",
      "1.3256840649867863 life\n",
      "1.3126229923130972 series\n",
      "1.3012509898392406 great\n",
      "1.2966869892539765 her\n",
      "1.294543525403217 war\n",
      "1.291783898436456 perfect\n",
      "1.2895192470320413 highly\n",
      "1.2876191016779237 girl\n",
      "1.2876191016779237 cop\n",
      "1.2835973219904377 interesting\n",
      "1.282985599741782 loves\n",
      "1.2781122896220751 seasons\n",
      "1.2748435691416997 franz\n",
      "1.274646736041206 show\n",
      "==========\n",
      "Important words NEGATIVE\n",
      "0.6701384845929526 sizing\n",
      "0.6964955195094952 leaking\n",
      "0.7032834488432729 refund\n",
      "0.7075473340556688 griddle\n",
      "0.7075473340556688 valves\n",
      "0.7109232918785363 defective\n",
      "0.7139240736303036 waste\n",
      "0.7192917930856206 knob\n",
      "0.7203057176247516 email\n",
      "0.7203057176247516 melted\n",
      "0.7203057176247516 refunded\n",
      "0.721957878282555 disappointing\n",
      "0.7234544723499297 flame\n",
      "0.7344472420956532 useless\n",
      "0.7353956825674703 advertising\n",
      "0.7353956825674703 august\n",
      "0.7353956825674703 error\n",
      "0.7353956825674703 false\n",
      "0.7353956825674703 ie\n",
      "0.7353956825674703 perfectflow\n"
     ]
    }
   ],
   "source": [
    "v = CountVectorizer(min_df=2, max_df=.95)\n",
    "X = v.fit_transform(reviews.text)\n",
    "b = MultinomialNB()\n",
    "b.fit(X, y)\n",
    "important_features(v, b, n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SelectKBest feature selector can take a ranking function as an input -- previously we used the built-in ranker mutual information, but we can use the probability ratio instead.  In this case a feature is more significant the farther away from 1 it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Signature is dictated by SelectKBest -- \n",
    "#  \"Function taking two arrays X and y, and returning a pair of arrays (scores, pvalues) or a single array with scores\"\n",
    "\n",
    "# Returns a vector of scores for each feature based on the score ratio\n",
    "def prob_ratio_score(X, y):\n",
    "    b = MultinomialNB()\n",
    "    b.fit(X, y)\n",
    "    log_prob_frac = log_prob_ratios(b)\n",
    "    return abs(log_prob_frac - 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2687, 7230)\n",
      "(2687, 2000)\n"
     ]
    }
   ],
   "source": [
    "#  Now we can select the K best features based on the ratio.  Just for a reality check:  \n",
    "#  this transform should reduce the number of features from 14.8K to 2K\n",
    "v = CountVectorizer(min_df=2, max_df=.95)\n",
    "X = v.fit_transform(reviews.text)\n",
    "kbest = SelectKBest(prob_ratio_score, k=2000)\n",
    "XX = kbest.fit_transform(X, y)\n",
    "print(X.shape)\n",
    "print(XX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9065860289629919\n",
      "0.9177509293680297\n"
     ]
    }
   ],
   "source": [
    "# And here is our head-to-head comparison.  Same classifier, same vectorizer, same \n",
    "#  number of features, but we just rank the features differently\n",
    "v = CountVectorizer(min_df=2, max_df=.95)\n",
    "\n",
    "print(k_features_accuracy(3000, MultinomialNB(), v.fit_transform(reviews.text), y))\n",
    "print(k_features_accuracy(3000, MultinomialNB(), v.fit_transform(reviews.text), y, prob_ratio_score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------\n",
    "\n",
    "### Examining Misclassified Instances\n",
    "\n",
    "1. Find some misclassified instances\n",
    "2. Visually, can we see anything that would make us worry or not worry?\n",
    "3. If the reason for misclassification isn't obvious, look more closely at the words and their scores according to the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9177509293680297\n",
      "[[ 330   41]\n",
      " [  83 2233]]\n",
      "0.9538518794194268\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# This is our baseline best classifier.\n",
    "b = MultinomialNB()\n",
    "v = CountVectorizer(min_df=2, max_df=.95)\n",
    "X = v.fit_transform(reviews.text)\n",
    "kbest = SelectKBest(prob_ratio_score, k=3000)\n",
    "X = kbest.fit_transform(X, y)\n",
    "eval_test_set(b, Xnew, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[45, (1, 0)],\n",
       "       [54, (1, 0)],\n",
       "       [104, (1, 0)],\n",
       "       [121, (1, 0)],\n",
       "       [129, (1, 0)],\n",
       "       [160, (1, 0)],\n",
       "       [165, (1, 0)],\n",
       "       [188, (1, 0)],\n",
       "       [215, (0, 1)],\n",
       "       [218, (0, 1)],\n",
       "       [227, (1, 0)],\n",
       "       [303, (1, 0)],\n",
       "       [309, (1, 0)],\n",
       "       [314, (1, 0)],\n",
       "       [353, (0, 1)],\n",
       "       [354, (1, 0)],\n",
       "       [358, (1, 0)],\n",
       "       [407, (1, 0)],\n",
       "       [411, (1, 0)],\n",
       "       [414, (1, 0)],\n",
       "       [421, (1, 0)],\n",
       "       [433, (0, 1)],\n",
       "       [443, (0, 1)],\n",
       "       [453, (0, 1)],\n",
       "       [464, (1, 0)],\n",
       "       [514, (1, 0)],\n",
       "       [516, (0, 1)],\n",
       "       [547, (1, 0)],\n",
       "       [548, (0, 1)],\n",
       "       [566, (1, 0)],\n",
       "       [595, (0, 1)],\n",
       "       [623, (1, 0)],\n",
       "       [625, (1, 0)],\n",
       "       [663, (0, 1)],\n",
       "       [670, (1, 0)],\n",
       "       [685, (0, 1)],\n",
       "       [709, (0, 1)],\n",
       "       [730, (1, 0)],\n",
       "       [765, (1, 0)],\n",
       "       [817, (0, 1)],\n",
       "       [827, (0, 1)],\n",
       "       [846, (1, 0)],\n",
       "       [866, (0, 1)],\n",
       "       [899, (1, 0)],\n",
       "       [925, (1, 0)],\n",
       "       [926, (1, 0)],\n",
       "       [951, (0, 1)],\n",
       "       [979, (1, 0)],\n",
       "       [1044, (0, 1)],\n",
       "       [1050, (1, 0)],\n",
       "       [1062, (1, 0)],\n",
       "       [1067, (0, 1)],\n",
       "       [1088, (1, 0)],\n",
       "       [1115, (1, 0)],\n",
       "       [1133, (1, 0)],\n",
       "       [1147, (0, 1)],\n",
       "       [1252, (0, 1)],\n",
       "       [1253, (0, 1)],\n",
       "       [1266, (0, 1)],\n",
       "       [1304, (1, 0)],\n",
       "       [1344, (1, 0)],\n",
       "       [1346, (0, 1)],\n",
       "       [1375, (0, 1)],\n",
       "       [1380, (1, 0)],\n",
       "       [1441, (1, 0)],\n",
       "       [1478, (0, 1)],\n",
       "       [1494, (1, 0)],\n",
       "       [1512, (1, 0)],\n",
       "       [1518, (1, 0)],\n",
       "       [1523, (1, 0)],\n",
       "       [1596, (0, 1)],\n",
       "       [1617, (1, 0)],\n",
       "       [1641, (1, 0)],\n",
       "       [1659, (0, 1)],\n",
       "       [1693, (0, 1)],\n",
       "       [1720, (1, 0)],\n",
       "       [1740, (1, 0)],\n",
       "       [1759, (1, 0)],\n",
       "       [1769, (0, 1)],\n",
       "       [1779, (1, 0)],\n",
       "       [1788, (1, 0)],\n",
       "       [1814, (1, 0)],\n",
       "       [1862, (1, 0)],\n",
       "       [1916, (1, 0)],\n",
       "       [1933, (0, 1)],\n",
       "       [1942, (1, 0)],\n",
       "       [1952, (0, 1)],\n",
       "       [1969, (0, 1)],\n",
       "       [2030, (1, 0)],\n",
       "       [2048, (0, 1)],\n",
       "       [2051, (1, 0)],\n",
       "       [2065, (1, 0)],\n",
       "       [2086, (1, 0)],\n",
       "       [2141, (1, 0)],\n",
       "       [2148, (1, 0)],\n",
       "       [2161, (0, 1)],\n",
       "       [2162, (1, 0)],\n",
       "       [2182, (1, 0)],\n",
       "       [2196, (0, 1)],\n",
       "       [2198, (1, 0)],\n",
       "       [2207, (1, 0)],\n",
       "       [2210, (1, 0)],\n",
       "       [2231, (1, 0)],\n",
       "       [2244, (1, 0)],\n",
       "       [2258, (1, 0)],\n",
       "       [2269, (1, 0)],\n",
       "       [2281, (1, 0)],\n",
       "       [2338, (0, 1)],\n",
       "       [2356, (1, 0)],\n",
       "       [2407, (0, 1)],\n",
       "       [2410, (1, 0)],\n",
       "       [2433, (1, 0)],\n",
       "       [2443, (0, 1)],\n",
       "       [2447, (1, 0)],\n",
       "       [2451, (1, 0)],\n",
       "       [2478, (1, 0)],\n",
       "       [2488, (0, 1)],\n",
       "       [2500, (1, 0)],\n",
       "       [2523, (1, 0)],\n",
       "       [2526, (1, 0)],\n",
       "       [2559, (0, 1)],\n",
       "       [2621, (1, 0)],\n",
       "       [2650, (0, 1)],\n",
       "       [2668, (1, 0)]], dtype=object)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Get indices of some misclassified instances.  Remember that\n",
    "#  the index (observation #) is the same in X, y\n",
    "b.fit(X, y)\n",
    "pred = b.predict(X)\n",
    "mask = pred != np.array(y)\n",
    "misclassed = np.array(list(zip(range(0,len(pred)), zip(y, pred))), dtype=object)\n",
    "misclassed[mask]\n",
    "\n",
    "# For example [167, (1, 0)] means that for example # 167, the actual value was 1 but we predicted 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reviewerID': 'A10MVE2MEOU6XT',\n",
       " 'asin': 'B002YLEPP4',\n",
       " 'reviewerName': 'Julie Schmidt',\n",
       " 'helpful': [7, 7],\n",
       " 'reviewText': 'I love popcorn seasoning, but they all mostly taste like salt.  This one tastes like white cheddar!  Imagine that.  I will never order the other kind again.',\n",
       " 'overall': 5.0,\n",
       " 'summary': 'Finally tastes like Cheese and not Salt!',\n",
       " 'unixReviewTime': 1297728000,\n",
       " 'reviewTime': '02 15, 2011'}"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Actual label is good (1), we classify bad (0)\n",
    "raw_training[45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9931769, 0.0068231])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.predict_proba(X)[45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True, ..., False, False,  True])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kbest.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Get the fitted classifier's term probabilities -- i.e the ratio P(term|class=0) / P(term|class=1)\n",
    "#  Remember that the classifier is working on a reduced set of features!\n",
    "#  The vectorizer knows the term names, but it stores the larger set of features so we have to \n",
    "def feature_log_prob(b, v, k):\n",
    "    # Select the feature names actually used by kbest\n",
    "    feature_names = np.array(v.get_feature_names())[k.get_support()]\n",
    "    log_prob_frac = b.feature_log_prob_[0] / b.feature_log_prob_[1]\n",
    "    return dict(zip(feature_names, log_prob_frac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#  Show the log prob ratio for the instance with this index.\n",
    "#  NOTE -- this is using values of b (classifier), v(vectorizer), and kbest(X with reduced features)\n",
    "\n",
    "def show_scores_for(index, b, v, k):\n",
    "    # Mapping of term to log prob (all possible features)\n",
    "    flp = feature_log_prob(b,v,k)\n",
    "    # Feature names, only the k best\n",
    "    feature_names = np.array(v.get_feature_names())[k.get_support()]\n",
    "    # Term values (just a count) \n",
    "    termvals = X[index].toarray().ravel()\n",
    "    scores = []\n",
    "    for i in range(0, termvals.shape[0]):\n",
    "        if termvals[i] > 0:\n",
    "            scores.append((feature_names[i], termvals[i], flp[feature_names[i]]))\n",
    "    return sorted(scores, key=lambda x: x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cheddar', 1, 0.7654402763756577),\n",
       " ('popcorn', 1, 0.8183403641569169),\n",
       " ('not', 1, 0.86830103806625),\n",
       " ('salt', 2, 0.8692725476680273),\n",
       " ('seasoning', 1, 0.8843338888106116),\n",
       " ('white', 1, 0.9025628768237343),\n",
       " ('cheese', 1, 0.9096996960582528),\n",
       " ('never', 1, 0.9395533152410037),\n",
       " ('finally', 1, 0.9426429080654279),\n",
       " ('this', 1, 1.0829906343584939),\n",
       " ('and', 1, 1.1305001378416628),\n",
       " ('mostly', 1, 1.2033999126536807),\n",
       " ('love', 1, 1.4220501766557792)]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_scores_for(45, b, v, kbest)\n",
    "# These are the term scores for the short review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.26126554, 0.73873446])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a misprediction where label is bad but we predicted good\n",
    "b.predict_proba(Xnew)[817]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reviewerID': 'A1DZT5D7BNDY5H',\n",
       " 'asin': '1580626513',\n",
       " 'reviewerName': 'Teacher Jan',\n",
       " 'helpful': [4, 7],\n",
       " 'reviewText': \"This is not going to help you learn to play.  It is filled with a lot of useless information.  Don't buy it, unless you just want to read about playing the piano or keyboard.\",\n",
       " 'overall': 1.0,\n",
       " 'summary': 'Useless book',\n",
       " 'unixReviewTime': 1142726400,\n",
       " 'reviewTime': '03 19, 2006'}"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_training[817]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('useless', 2, 0.7156815258710432),\n",
       " ('not', 1, 0.86830103806625),\n",
       " ('unless', 1, 0.8707862888834099),\n",
       " ('keyboard', 1, 0.9096996960582528),\n",
       " ('don', 1, 0.9327382252209842),\n",
       " ('play', 1, 1.0525643072983926),\n",
       " ('with', 1, 1.0562614222870694),\n",
       " ('is', 2, 1.058512107946147),\n",
       " ('playing', 1, 1.0656065366015852),\n",
       " ('to', 3, 1.0729113494759033),\n",
       " ('you', 2, 1.0774858909505538),\n",
       " ('this', 1, 1.0829906343584939),\n",
       " ('learn', 1, 1.0838206109476933),\n",
       " ('piano', 1, 1.0898975237904718),\n",
       " ('of', 1, 1.0910289504160224),\n",
       " ('lot', 1, 1.154781756017009),\n",
       " ('read', 1, 1.180599373217057),\n",
       " ('book', 1, 1.2887365827535455)]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_scores_for(817, b, v, kbest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
